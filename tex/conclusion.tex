\twocolumn[
	\section{Conclusion}\label{ch:conclusion}
	]	

\noi	
Rapid progress in computational gains and mobile device technology has sparked a renewed interest in spatial interaction and a surge of innovation that is likely to soon challenge the traditional  ways of human-computer interaction. One possible technique for exploiting the space around a mobile device was explored in this work, by the concept of swiping outside the boundaries of a small mobile display. 

The main idea pursued was that the interacting space could be defined in a way that optimized the user experience, as formally captured by our hypothesis. To provide a foundation for confirmation or falsification, a solution was developed, implemented and data was collected through experiments, appropriately designed by drawing on lessons learned from existing research. A number of test subjects then interfaced with experimental tasks by completing trials using different  spatial interfaces, each  conceived on intuitive ideas of how users are likely to perceive the surrounding space. 

To define what constitutes a good off-screen interface, a number of  properties of the collected trial data were compared against each other. Reducing the interaction duration was assumed to be most relevant  and therefore chosen to serve as a primary indicator of an improved user experience. Secondary indicators of overshoot travel and touch count were also covered, to give some insight and measure into how accurate and effortless an interaction proceeds. 

What was learned from the  data, was that no off-screen interaction could outperform a   baseline restricted to on-screen input (with inertia) only, but that an interface based on spherical curvature of the surrounding space came very close. Furthermore, secondary indicators gave the clear impression that such off-screen inputs are without redundancy for all targets within physical reach, while also maintaining  full and continuous precision of movement throughout the interaction. These two indicators combined, and taking into consideration that the baseline is significantly advantaged by preexisting user experience, indicates that extending swipes into the surrounding space using such an interface does improve the overall user experience, thereby confirming the hypothesis.

%First, it was learned if there are general patterns in how users's perceive the off-screen space. 

Further attempts were made to bring the solution to a more refined form that could possibly do even better. Through a second experiment, it was confirmed that user inputs do appear spherical, but also that they differ greatly and have  properties that are more complex than what can be captured by a simple sphere. A subsequent modification then attempted to conform to these observed properties by introducing compression, rotation and a dynamic location of the mean, based on the collected data.  Evaluating this through a third experiment did in fact show a slight performance gain, although with some uncertainty due to a lower number of participants and possible spatial bias. 

%And finally, it would be relevant to uncover whether left-handed interactions are purely symmetrical to thr right for off-screen swipes. 

In all, the work undertaken here has contributed to the body knowledge through three experiments, that combined have illuminated interaction characteristics for when users incorporate the surrounding space into navigational tasks. This was done through a solution for interpreting spatial input that turned out to be on par, if not better, than only relying  on-screen input  for navigation. This spawns several new research questions, such as whether the solution can be further optimized by incorporating more complex features of the true space.  Also, comparing the result to a  different approach for spatial modification could be of interest, such as conforming to observed features by  minimizing some error  through gradients or perhaps parameter sweeping. These questions are  left to be explored through future work.

%Recent developments in computational gains combined with the ability to harvest, process and learn from data on a massive scale, have sparked renewed interest in computer vision and made for scientific leaps in its development and applicability. This has sparked a surge of innovation within a related field, human-computer interaction, as challenging the traditional ways of computer input is now a task overdue. Furthermore, the incentive to innovate is greatly amplified by yet another factor: the increasing tendency of manufacturers to incorporate low-cost computation in all areas of everyday life, including those that have previously been unimaginable due to a lack of appropriate interaction methods. 
%
%Hence, exploring possible opportunities for extending one recent innovation, touch input, in the form of the \AirSwipe\ concept, is justified on the basis of current computational standards, the anticipation of future sensory inputs and such undertaking would be in line with ongoing scientific efforts within the field of human-computer research.

